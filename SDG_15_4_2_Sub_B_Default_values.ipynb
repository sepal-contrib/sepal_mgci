{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyarnell/sepal_mgci/blob/master/SDG_15_4_2_Sub_B_Default_values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SDG 15.4.2 Subcomponent B: Calculate Global Default Values**\n",
        "\n",
        "* This script allows batch processing for this indicator for all countries.\n",
        "\n",
        "* Output is a combined excel file on your Google Drive.\n",
        "\n",
        "* Runs on the cloud using [Google Colab](https://research.google.com/colaboratory/faq.html)\n",
        "\n",
        "* Requires: [Google Earth Engine](https://earthengine.google.com/) (GEE) account and project and access to Google Drive\n"
      ],
      "metadata": {
        "id": "82FWR5yMh0HV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Install required packages"
      ],
      "metadata": {
        "id": "YdoCOI_1yWY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg3K1EPJu_f5",
        "outputId": "7825367d-f1ff-4b0b-ef34-4e97e1682384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hipyvuetify has been installed.\n",
            "ee is already installed.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hunidecode has been installed.\n",
            "google-api-python-client has been installed.\n"
          ]
        }
      ],
      "source": [
        "# to automatically reload modules.\n",
        "%load_ext autoreload\n",
        "\n",
        "# Set to reload all modules before executing code.\n",
        "%autoreload 2\n",
        "\n",
        "# Function to install a package if it's not already installed\n",
        "def install_if_not_exists(package_name):\n",
        "    try:\n",
        "        __import__(package_name)\n",
        "        print(f\"{package_name} is already installed.\")\n",
        "    except ImportError:\n",
        "        !pip install -q {package_name}\n",
        "        print(f\"{package_name} has been installed.\")\n",
        "\n",
        "# List of packages to install if not already installed\n",
        "packages_to_install = ['ipyvuetify','ee', 'unidecode', 'google-api-python-client',\n",
        "                      'google-auth-httplib2', 'google-auth-oauthlib']\n",
        "\n",
        "# Install necessary packages\n",
        "for package in packages_to_install:\n",
        "    install_if_not_exists(package)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Access GitHub repository\n",
        "Clones repository for SDG 15.4.2 into colab.\n",
        "Provides functions and lookup tables etc."
      ],
      "metadata": {
        "id": "qGfLFLEkwS1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the current working directory to \"/content\" for cloning the repo into.\n",
        "%cd \"/content\"\n",
        "\n",
        "# Clone the GitHub repository \"sepal_mgci\" into the current directory.\n",
        "# NB 'fatal' error on reruns are typically just saying it already exists\n",
        "# !git clone https://github.com/sepal-contrib/sepal_mgci\n",
        "\n",
        "!git clone https://github.com/andyarnell/sepal_mgci\n",
        "\n",
        "# Change working directory to the cloned sepal_mgci github repository\n",
        "%cd \"/content/sepal_mgci\""
      ],
      "metadata": {
        "id": "TNohZrOTvNqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Setup Google Earth Engine\n",
        "Launches access request pop up window"
      ],
      "metadata": {
        "id": "FAzzmzMHzFmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Earth Engine project\n",
        "gee_project_name = \"ee-andyarnellgee\" # \"insert cloud project here\"  # a registered cloud project (if unsure of name see pic here: https://developers.google.com/earth-engine/cloud/assets)\n",
        "\n",
        "import ee # google earth engine\n",
        "\n",
        "ee.Authenticate()\n",
        "\n",
        "ee.Initialize(project=gee_project_name) # NB gee project name is defined in parameters section"
      ],
      "metadata": {
        "id": "gHI-M8y_qwaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Setup Google Drive\n",
        "Launches access request pop up window"
      ],
      "metadata": {
        "id": "aUVGL6zwLpX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for accessing google drive\n",
        "from google.colab import auth, drive\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NorUzAJ8Kj0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Import remaining packages"
      ],
      "metadata": {
        "id": "L5jsWgqWyiCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from component.scripts.colab_imports import * # import all packages listed in the imports.py script"
      ],
      "metadata": {
        "id": "2Wquh4ZQbgfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) Set parameters\n"
      ],
      "metadata": {
        "id": "Bi0XpRRDo6V1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input parameters"
      ],
      "metadata": {
        "id": "5aIr_OxkG-Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Admin boundaries asset\n",
        "admin_asset_id = \"FAO/GAUL/2015/level0\" # administrative units feature collection\n",
        "\n",
        "admin_asset_property_name = \"ADM0_NAME\" # property/column name for selecting admin boundaries (e.g. ISO3 code or country name)\n",
        "\n",
        "\n",
        "# Land cover assets\n",
        "\n",
        "# For SUB_B indicator, we need to set the following structure\n",
        "sub_b_year = {\n",
        "    \"baseline\": {\n",
        "        \"base\": {\n",
        "            \"asset\": \"users/amitghosh/sdg_module/esa/cci_landcover/2000\",\n",
        "            \"year\": 2000,\n",
        "        },\n",
        "        \"report\": {\n",
        "            \"asset\": \"users/amitghosh/sdg_module/esa/cci_landcover/2015\",\n",
        "            \"year\": 2015,\n",
        "        },\n",
        "    },\n",
        "    # And the reporting year\n",
        "    2: {\"asset\": \"users/amitghosh/sdg_module/esa/cci_landcover/2018\", \"year\": 2018},\n",
        "}\n"
      ],
      "metadata": {
        "id": "t9C1qT5bGoqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output parameters\n",
        "- NB if no CSVs are being created, check that 'export = True' below.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "naz3Qe4JHFER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_report_folder = \"sdg_15_4_2_B_combined_report\" # folder name in Google Drive for final output (if doesnt exist creates one)\n",
        "\n",
        "final_report_name = \"sdg_15_4_2_B_default_global.xlsx\" # file name for final excel output\n",
        "\n",
        "# export GEE tasks or not\n",
        "export = True # default: True. Set to False if debugging or limiting accidental re-exporting of tasks\n",
        "\n",
        "# prints more messages\n",
        "debug = False # default: False. Set to True if debugging code"
      ],
      "metadata": {
        "id": "mSvTM29TnndR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temporary output parameters\n"
      ],
      "metadata": {
        "id": "iV8-wbddOJuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats_csv_folder = \"sdg_15_4_2_B_csvs\" # for storing stats tables exported from GEE for each admin boundary/AOI\n",
        "\n",
        "excel_reports_folder = \"sdg_15_4_2_B_reports\" # for storing formatted excel tables for each admin boundary/AOI\n",
        "\n",
        "drive_home =\"/content/drive/MyDrive/\" # Google Drive location. Don't change unless you know this is incorrect\n",
        "\n",
        "error_log_file_path = drive_home + excel_reports_folder + \"/\"+\"1_error_log\" +\".csv\" # for storing errors\n"
      ],
      "metadata": {
        "id": "TCBNkALuOL1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7) Setup inputs for processing"
      ],
      "metadata": {
        "id": "dVfL5w0eBi4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create list of boundaries to process"
      ],
      "metadata": {
        "id": "qi5zNGTWN3df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# admin boundary feature collection\n",
        "admin_boundaries = ee.FeatureCollection(admin_asset_id)\n",
        "\n",
        "# list to process\n",
        "list_of_countries = admin_boundaries.aggregate_array(admin_asset_property_name).getInfo()\n",
        "\n",
        "print (\"Length of admin boundaries to process\", len(list_of_countries))\n",
        "\n",
        "list_of_countries = list(set(list_of_countries)) # remove dupicates\n",
        "\n",
        "print (\"Length of distinct admin boundaries to process\", (len(set(list_of_countries))))\n"
      ],
      "metadata": {
        "id": "BiuBEJwPue2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the default land cover remapping table and convert it to a dictionary"
      ],
      "metadata": {
        "id": "2G1q9TSiUsc1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRSEqq5bu_f7"
      },
      "outputs": [],
      "source": [
        "default_map_matrix = map_matrix_to_dict(LC_MAP_MATRIX)\n",
        "\n",
        "# Set the defauult transition matrix path\n",
        "default_transition_matrix_path = TRANSITION_MATRIX_FILE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select years of land cover to process"
      ],
      "metadata": {
        "id": "4-Ut_-S35Yg8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwqJFWR4u_f7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# extracts the years from the b_years dictionary\n",
        "years = get_b_years(sub_b_year)\n",
        "years"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8) Calculate area statistics by country\n",
        "* Runs for each country and each mountain biobelt\n",
        "* Gets area of land cover reclassified into the 10 SEAM classes\n",
        "* Repeat for each year specified\n"
      ],
      "metadata": {
        "id": "iNxHtR984cNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VftKLuY4u_f7"
      },
      "outputs": [],
      "source": [
        "# you can monitor your GEE tasks here : https://code.earthengine.google.com/tasks\n",
        "\n",
        "create_folder_if_not_exists(stats_csv_folder) # to store outputs in google drive\n",
        "\n",
        "counter=0 # starting place of counter used to keep track of number of tasks that are being run\n",
        "\n",
        "for aoi_name in list_of_countries:\n",
        "\n",
        "  aoi = admin_boundaries.filter(ee.Filter.eq(admin_asset_property_name,aoi_name))#.first()\n",
        "\n",
        "  process = ee.FeatureCollection([\n",
        "      ee.Feature(\n",
        "          None,\n",
        "          reduce_regions(\n",
        "              aoi,\n",
        "              remap_matrix=default_map_matrix,\n",
        "              rsa=False,\n",
        "              dem=DEM_DEFAULT, #default digital elevation model (DEM). Relevant for the real surface area (RSA) implementation.\n",
        "              lc_years= year,\n",
        "              transition_matrix=default_transition_matrix_path # a matrix of transitions between land cover classes. Used to assess if change between two inputs is to a different (e.g. degraded) state\n",
        "          )\n",
        "      ).set(\"process_id\", \"_\".join([str(y[\"year\"]) for y in year]))\n",
        "  for year in years # creates GEE images for each year listed and counts areas under different transitions Subindicator B. Images to run are in the 'b_years\" dictionary (above)\n",
        "  ])\n",
        "  #make name acceptable for running tasks (i.e., removes special characters)\n",
        "  task_name = str(sanitize_description(unidecode(aoi_name)))\n",
        "\n",
        "  task = ee.batch.Export.table.toDrive(\n",
        "      **{  #asterisks unpack dictionary into keyword arguments format\n",
        "          \"collection\": process,\n",
        "          \"description\": task_name,\n",
        "          \"fileFormat\": \"CSV\",\n",
        "          \"folder\":stats_csv_folder\n",
        "      }\n",
        "  )\n",
        "\n",
        "  counter+=1\n",
        "\n",
        "  print (f\"\\r process {counter}/{len(list_of_countries)} {aoi_name} \", end=\"\") #print in place (remove \\r and end=\"\" for verbose version)\n",
        "\n",
        "  if export:\n",
        "    task.start()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM0SIvJtu_f8"
      },
      "source": [
        "### 9) Read and translate results into report tables"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Manually check your earth engine task status, once the tasks are complete, run the next cell. https://code.earthengine.google.com/tasks\n",
        "\n",
        "This formats individual excel reports for each country.\n",
        "See Error_log.csv for missing files/errors"
      ],
      "metadata": {
        "id": "3x7jwkZJWwE-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkpDfHqQu_f9"
      },
      "outputs": [],
      "source": [
        "# Initialize the counter\n",
        "counter = 0\n",
        "\n",
        "# to store outputs in google drive\n",
        "create_folder_if_not_exists(excel_reports_folder)\n",
        "\n",
        "# Loop over each AOI name in the list of countries\n",
        "for aoi_name in list_of_countries:\n",
        "    counter += 1\n",
        "\n",
        "    # Clean the AOI name\n",
        "    aoi_name_clean = str(sanitize_description(unidecode(aoi_name)))\n",
        "\n",
        "    # Construct the file path for the stats CSV file\n",
        "    stats_csv_file = aoi_name_clean + \".csv\"\n",
        "    stats_csv_file_path = os.path.join(drive_home, stats_csv_folder, stats_csv_file)\n",
        "\n",
        "    message = f\"Process {counter}, {stats_csv_file}\"\n",
        "\n",
        "    try:\n",
        "        # Read the results from the CSV file and parse it to a dictionary\n",
        "        dict_results = read_from_csv(stats_csv_file_path)\n",
        "\n",
        "        # details = {\n",
        "        #     \"geo_area_name\": aoi_name,\n",
        "        #     \"ref_area\": \" \",\n",
        "        #     \"source_detail\": \" \",\n",
        "        # }\n",
        "\n",
        "        sub_b_reports = []\n",
        "        reporting_years_sub_b = get_reporting_years(sub_b_year, \"sub_b\")\n",
        "        _, sub_b_years = get_sub_b_items(reporting_years_sub_b)\n",
        "\n",
        "        for year in sub_b_years:\n",
        "            print(f\"Reporting {year} for sub_b\")\n",
        "            # Get year label for the report\n",
        "            parsed_df = parse_to_year(dict_results, year)\n",
        "            sub_b_reports.append(\n",
        "                sub_b.get_reports(\n",
        "                    parsed_df,\n",
        "                    year,\n",
        "                    geo_area_name = aoi_name,\n",
        "                    ref_area = \"\",\n",
        "                    source_detail = \"\",\n",
        "                    transition_matrix = default_transition_matrix_path\n",
        "                ))\n",
        "        # sub b reports\n",
        "        er_mtn_dgrp_df = pd.concat([report[0] for report in sub_b_reports])\n",
        "        er_mtn_dgda_df = pd.concat([report[1] for report in sub_b_reports])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Define the output report file path\n",
        "        report_file_path = os.path.join(drive_home, excel_reports_folder, aoi_name_clean + \".xlsx\")\n",
        "\n",
        "        # This will create the excel file with the reports\n",
        "        with pd.ExcelWriter(report_file_path) as writer:\n",
        "            er_mtn_dgda_df.to_excel(writer, sheet_name=\"Table4_ER_MTN_DGRDA\", index=False)\n",
        "            er_mtn_dgrp_df.to_excel(writer, sheet_name=\"Table5_ER_MTN_DGRDP\", index=False)\n",
        "\n",
        "            for sheetname in writer.sheets:\n",
        "                worksheet = writer.sheets[sheetname]\n",
        "                for col in worksheet.columns:\n",
        "                    max_length = 0\n",
        "                    column = col[0]\n",
        "                    for cell in col:\n",
        "                        try:\n",
        "                            if len(str(cell.value)) > max_length:\n",
        "                                max_length = len(cell.value)\n",
        "                        except:\n",
        "                            pass\n",
        "                    adjusted_width = max(max_length, len(str(column.value))) + 4\n",
        "                    worksheet.column_dimensions[get_column_letter(column.column)].width = (\n",
        "                        adjusted_width\n",
        "                    )\n",
        "\n",
        "                    # Align \"obs_value\" column to the right\n",
        "                    if \"OBS\" in column.value:\n",
        "                        for cell in col:\n",
        "                            cell.alignment = Alignment(horizontal=\"right\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        # If an error occurs, catch the exception and handle it\n",
        "        message = f\"process {counter}, {stats_csv_file}, Error: {e}\"\n",
        "\n",
        "        # Get the current time\n",
        "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # Write the error message and file name to the error log file\n",
        "        error_info = pd.DataFrame([[stats_csv_file, str(e), current_time]], columns=['File Name', 'Error Message', 'Time'])\n",
        "\n",
        "        mode = 'w' if not os.path.exists(error_log_file_path) else 'a'\n",
        "        header = False if os.path.exists(error_log_file_path) else True\n",
        "\n",
        "        # Append or write to the error log file\n",
        "        error_info.to_csv(error_log_file_path, mode=mode, header=header, index=False)\n",
        "\n",
        "    print(message)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10) Combine excel report files into one"
      ],
      "metadata": {
        "id": "qTqI3Ag08k5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a list of files to combine"
      ],
      "metadata": {
        "id": "sVpLtG4Z7Jbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory path where Excel reports are stored\n",
        "directory_path = os.path.join(drive_home, excel_reports_folder)\n",
        "\n",
        "# List files in the directory with '.xlsx' extension\n",
        "files = [file for file in os.listdir(directory_path) if file.endswith('.xlsx')]\n",
        "\n",
        "# Create a list of full file paths\n",
        "full_file_paths = [os.path.join(directory_path, file) for file in files]\n",
        "\n",
        "# Print the number of Excel files found in the folder\n",
        "print(f\"Number of Excel files in folder: {len(full_file_paths)}\")\n",
        "\n",
        "# folder to store outputs in google drive\n",
        "create_folder_if_not_exists(final_report_folder)\n",
        "\n",
        "# File path for the combined final report\n",
        "reports_combined_file_path = os.path.join(drive_home, final_report_folder, final_report_name)\n"
      ],
      "metadata": {
        "id": "sTyhwne7rr9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Run function to combine into a single report"
      ],
      "metadata": {
        "id": "C77flAQu7xWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "append_excel_files(file_paths=full_file_paths,num_sheets=3,output_file_path=reports_combined_file_path)\n",
        "\n",
        "print (f\"\\n Complete! Output file for SDG 15.4.2 Component A here: {reports_combined_file_path}\")"
      ],
      "metadata": {
        "id": "FkS1ErA9AYj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "(test) test-sepal_mgci",
      "language": "python",
      "name": "test-sepal_mgci"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}